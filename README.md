# FPGA-Based-AI-Hardware-Accelerator-Integrated-with-RISC-V-SoC-for-Silicon-Wafer-Defect-Detection

üöÄ Project Overview

This project presents a custom AI hardware accelerator designed for real-time wafer defect detection in semiconductor manufacturing.
It targets deployment on an FPGA-based RISC-V VEGA SoC, integrating a MobileNetV2-inspired CNN optimized for low power, high throughput edge inference.
Traditional cloud or HPC-based wafer inspection systems are too power-hungry and costly for fab-floor use.
Our FPGA-based accelerator overcomes these limitations with an energy-efficient, parallelized, and quantized design suitable for edge deployment.

üß© System Architecture

üî∏ Processor Platform

RISC-V VEGA Core (AT1051): 32-bit in-order processor for configuration, control, and result retrieval.

AXI4-Lite & AXI4-Full Interfaces for seamless integration between control and high-throughput data paths.

üî∏ Accelerator Components

STCE ‚Äì Standard Convolution Engine (3√ó3): For low-level spatial feature extraction.

DWCE ‚Äì Depthwise Convolution Engine: Channel-wise lightweight convolution for efficient filtering.

PWCE ‚Äì Pointwise Convolution Engine (1√ó1): Performs channel mixing and dimensionality adjustment.

Auxiliary Modules:

Batch Normalization

ReLU6 Activation (quantization-friendly)

Max Pooling (2√ó2, 7√ó7)

Flatten + Fully Connected Layers

ArgMax Classification Logic

üî∏ Data Movement

On-chip BRAM: For intermediate activations and feature maps.

DDR3 External Memory (future work): For dynamic loading of inputs and model weights.

AXI4 DMA planned for high-speed streaming.

üìà Model and Dataset

Model: MobileNetV2 (Quantization-Aware Trained)

Precision: FP32 ‚Üí INT8 via Quantization-Aware Training (QAT)

Dataset: WM-811K / LSWMD (Wafer Map Dataset)

Classes (9 Total):

Center, Donut, Edge-Loc, Edge-Ring, Loc, Near-Full, Random, Scratch, None

Accuracy: ~91.7% (INT8, close to FP32)

Inference Latency: 161 ms per 224√ó224 image

Throughput: 6.21 FPS

Speedup: 8.68√ó vs. software implementation

‚öôÔ∏è Functional Specifications

| Specification        | Details                                            |
| -------------------- | -------------------------------------------------- |
| **Input**            | 224√ó224√ó3 wafer images (RGB)                       |
| **Output**           | 9 defect class labels                              |
| **Processor**        | RISC-V                                             |
| **Interface**        | AXI4-Lite (control), AXI4-Full (data)              |
| **Tools**            | Xilinx Vivado, Verilog/SystemVerilog, Google Colab |
| **Precision**        | INT8 quantized (QAT-trained)                       |
| **Power Efficiency** | Reduced memory access via on-chip BRAM             |
| **Scalability**      | Supports higher-resolution inputs and CNN variants |

üèóÔ∏è Design Flow

1. Model Training & Quantization

Trained MobileNetV2 using Google Colab on the WM-811K wafer dataset.

Applied Quantization-Aware Training to achieve INT8 inference accuracy close to FP32.

2. Hardware Accelerator Design

Designed modular convolution engines (STCE, DWCE, PWCE) using Verilog.

Developed FSM-based control logic for layer sequencing and synchronization.

Implemented intra-layer and inter-layer pipelining for maximum throughput.

3. SoC Integration

Integrated with RISC-V via AXI4-Lite slave interface.

Implemented register-based control mechanism for accelerator start/done signaling.

Used .mem and .hex files for simulation data (weights, biases, input images).

4. Simulation & Verification

Verified on Vivado simulation using modified matrix-multiplication C testbench.

Validated full AXI transaction flow:

Write command (start)

Accelerator compute

Done flag assertion

Read back classification result

Integration of AI Hardware Accelerator with RISC-V SoC via AXI Interface
The proposed system integrates a quantized CNN accelerator with a RISC-V SoC using an AXI interface to enable high-speed wafer defect classification for real-time semiconductor manufacturing environments. The design achieves low latency, high throughput, and efficient parallelism, enabling edge-deployed inspection.
CNN Binary Configuration & HyperRAM Program Flow
‚Ä¢	The CNN module is configured with the help of a binary (.bin) command file stored on an SD card.
‚Ä¢	This .bin file is a command sequence stream generated by the Lattice Machine Learning Tool.
‚Ä¢	The command code is first written into HyperRAM via AXI before the CNN Accelerator IP core begins execution.
‚Ä¢	During execution, CNN fetches command code from HyperRAM and performs internal operations accordingly.
‚Ä¢	Intermediate feature maps and activation tensors may also be exchanged between CNN and HyperRAM based on command flow.
‚Ä¢	RAW8 pixel input from the csi2_to_parallel interface is downscaled to 224√ó224 resolution via the crop_downscale_front_224x224 module.
‚Ä¢	This preprocessed 224√ó224 data is written into HyperRAM through the axi2_hyperbus bridge via axi_ws2m AXI interconnect.
‚Ä¢	Once both command file & image data are valid, the accelerator is triggered at the rising edge of cnn_start.
Image Sensor and Camera Link
The image sensor acts as the direct capture input source via the board‚Äôs camera connector.
Data transfer between the sensor and CertusPro-NX uses CSI-2 protocol.
Camera configuration and control registers are driven through I¬≤C issued by the CertusPro-NX SoC.


Firmware and Host Integration
A lightweight firmware program runs on the Vega RISC-V core to control the CNN accelerator. This firmware is compiled using the RISC-V GCC toolchain (Ubuntu WSL) and uploaded to the Lattice FPGA board.
1.	Firmware Compilation & Deployment
Developer compiles using riscv64-unknown-elf-gcc
ELF is delivered via bootloader or UART
2.	Image Preprocessing & Conversion
Wafer images preprocessed externally
Converted to HEX tensors (224√ó224√ó3)
3.	Loading Image to Accelerator RAM
Firmware performs AXI burst writes to CNN RAM
4.	Configuring the CNN Accelerator
Firmware writes: start ‚Üí layer_id ‚Üí mode ‚Üí base addresses of weights/biases ‚Üí QAT scale/shift parameters
5.	Execution & Polling
Accelerator start asserted
Firmware polls done flag
6.	Prediction Retrieval
Defect class output read from accelerator register bank
SPI Bootloader and HyperRAM Memory Loading 
‚Ä¢	The spi_loader_spram RTL block performs SPI Flash read accesses and streams the content into HyperRAM using AXI.
‚Ä¢	On device power-up, .bit (FPGA image) and .bin (CNN ML command sequence) are auto-loaded to predefined memory ranges:
o	BIT File Address Range: 0x0000000 ‚Äì 0x00100000
o	Firmware Range: FLASH_START_ADDR ‚Äì FLASH_END_ADDR
‚Ä¢	AXI logic performs 128-byte √ó 4-burst write transactions to HyperRAM.
‚Ä¢	axi_ws2m multiplexes multiple AXI write requestors:
o	Slave 0 = spi_loader_spram (highest priority) to guarantee CNN binary availability
‚Ä¢	After each 512-byte segment is written, fetch continues until firmware end address is reached.
User Input and SoC Interface
‚Ä¢	RISC-V machine instructions feed the SoC.
‚Ä¢	Commands are decoded to determine:
Standard pipeline CPU operation
CNN acceleration trigger ‚Üí DMA image movement ‚Üí inference start
Instruction Dispatch and Pipeline Execution
AXI-Based Instruction Flow
Instructions and data are communicated between the SoC, RISC-V CPU, and CNN accelerator via AXI.
Key AXI Signals
‚Ä¢	Write Address Channel : m_axi_awid, m_axi_awvalid, m_axi_awlen, m_axi_awsize, m_axi_awburst, m_axi_awaddr, m_axi_awprot
‚Ä¢	Write Data Channel : m_axi_wdata, m_axi_wstrb, m_axi_wlast, m_axi_wvalid
‚Ä¢	Write Response Channel : m_axi_bready, s_axi_bvalid, s_axi_bresp, s_axi_bid
‚Ä¢	Read Address Channel : m_axi_arid, m_axi_arvalid, m_axi_arlen, m_axi_arsize, m_axi_araddr, m_axi_arprot
‚Ä¢	Read Data Channel : m_axi_rready, s_axi_rdata, s_axi_rid, s_axi_rresp, s_axi_rvalid, s_axi_rlast

AXI Interface Functions
‚Ä¢	Provides high-speed communication between modules.
‚Ä¢	Manages burst transfers for images, weights, and intermediate feature maps.
‚Ä¢	Prevents bus contention via ready/valid handshake signals.
‚Ä¢	Ensures correct synchronization of data streams during deep CNN pipeline execution.

RISC-V Pipeline Behavior
‚Ä¢	IF: Fetch instructions.
‚Ä¢	ID: Detect CNN accelerator instruction.
‚Ä¢	EX: CPU executes normal instruction or triggers CNN operation.
‚Ä¢	MEM: Performs AXI-based memory transfers.
‚Ä¢	WB: Writes back CPU results; CNN results go to SoC via AXI.

CNN Accelerator Dataflow
Bootloader ROM Functions
‚Ä¢	Stores frequently used:
o	Input template vectors
o	Quantized weights & biases
o	Scale/shift QAT parameters
Data Movement
‚Ä¢	Images are written to CNN RAM using AXI burst transactions.
‚Ä¢	Accelerator accesses weights, biases, and intermediate activations locally.
Internal Architecture
‚Ä¢	Standard Convolution Engine
‚Ä¢	Depthwise Convolution Engine
‚Ä¢	Pointwise Convolution Engine
‚Ä¢	Batch Normalization Unit
‚Ä¢	ReLU6 Activation
‚Ä¢	Max Pooling Unit
Operational Modes
1.	Sequential Mode
o	Each image is processed fully before the next begins.
2.	Pipelined Mode
o	Multiple images overlap across CPU and CNN execution.
o	Maximizes overall system throughput.

Prediction Retrieval
‚Ä¢	After accelerator completes computation:
o	Prediction is stored in CNN accelerator RAM.
o	Retrieved by firmware through AXI reads.
o	Forwarded to the SoC, then to the user interface.

External Host Data Forwarding 
‚Ä¢	Output wafer features generated inside CertusPro-NX are transmitted to the CYUSB3014 USB3 bridge
‚Ä¢	CYUSB3014 packages & streams data to PC host for visualization and post-classification analytics.


5. FPGA Implementation

Platform: Lattice Semiconductor‚Äôs CertusPro-NX Voice and Vision Machine Learning Board

‚ö° Performance Analysis

| Metric                | Value                                           |
| --------------------- | ----------------------------------------------- |
| **Accuracy**          | 91.73% (INT8)                                   |
| **Throughput**        | 11.87 KFPS                                      |
| **Latency per Frame** | 84.25 ¬µs                                        |
| **Speedup**           | 223.68√ó                                         |
| **Clock Frequency**   | 200 MHz                                         |
| **Utilization**       | Resource-efficient BRAM + DSPs                  |
| **Power**             | Low power (due to INT8 ops + parallel PE array) |

The full pipeline, including feature extraction, dense, argmax, and prediction stages, completes in 16,850 cycles at 200 MHz, corresponding to 84.25 ¬µs latency per frame. The accelerator achieves 11.87 kFPS throughput, satisfying real-time inline inspection requirements. It provides a 223.68√ó speedup over software INT8 inference due to efficient depthwise‚Äìpointwise mapping and pipelined execution. Area utilization on CertusPro-NX FPGA is 14.1 mm¬≤, and on-chip dynamic power is 2.265 W with energy consumption of 190 ¬µJ per frame, making continuous 24/7 operation feasible. All computation is performed on-chip using BRAM buffers without DDR dependency, preventing bandwidth stalls. RISC-V integration allows direct accelerator control, prediction acknowledgment, and completion without external PC/GPU/cloud involvement, ensuring wafer data security. Deterministic execution with no OS jitter or external memory traffic meets strict fab timing constraints. The architecture supports scaling to larger wafer images or higher channel depth via tile-parallel acceleration, and the modular pipeline allows layer replacement, fusion, or expansion without redesigning memory or control logic. The accelerator sustains inline inspection rate with negligible delay compared to wafer imaging hardware.

üîç Significance

Real-time defect detection at the fab edge ‚Äî removing dependency on cloud/HPC.

Quantized lightweight design reduces energy and memory footprint.

RISC-V integration makes it scalable for open-source and reconfigurable SoCs.

Scalable architecture supports future CNN models and high-resolution inputs.

Enables on-site quality control, yield improvement, and predictive maintenance.

üîÆ Future Work

Hardware-aware CNN models for faster inference.

RISC-V AI extensions to accelerate convolutions natively.

Full DDR3 memory access for runtime weight/image loading.

Compute-in-Memory (CIM) extensions for ultra-low-power MAC operations.

ASIC Implementation for production-grade smart fab deployment.

Privacy-preserving inference for sensitive manufacturing data.

üß∞ Tools and Technologies

| Domain                    | Tools / Frameworks                                |
| ------------------------- | ------------------------------------------------- |
| **Hardware Design**       | Verilog, SystemVerilog, Vivado 2023.2             |
| **Processor Integration** | AXI4-Lite, AXI4-Full                              |
| **Model Training**        | TensorFlow, Google Colab                          |
| **Dataset**               | WM-811K / LSWMD                                   |
| **Target Hardware**       | Lattice Semiconductor‚Äôs CertusPro-NX Voice  Board |
| **Host Software**         | C-based firmware using AT1051 SDK                 |


This project successfully demonstrates a MobileNetV2-based FPGA AI Accelerator optimized for real-time wafer defect detection. The proposed modular design achieves:

Significant speedup and energy efficiency

INT8 inference accuracy near FP32

Seamless integration with RISC-V VEGA SoC

Scalable and modular architecture for future ASIC deployment

This research paves the way for on-fab, low-power, edge AI systems that enhance yield analysis and predictive maintenance in semiconductor manufacturing.

üìö References

M. Sandler et al., ‚ÄúMobileNetV2: Inverted Residuals and Linear Bottlenecks,‚Äù CVPR, 2018.

W. Jiang et al., ‚ÄúHigh-Throughput Full-Dataflow MobileNetv2 Accelerator on Edge FPGA,‚Äù IEEE TCAD, 2023.

M. Saqlain et al., ‚ÄúDeep CNN for Wafer Defect Identification,‚Äù IEEE TSM, 2020.

J. Huang et al., ‚ÄúHigh-Performance FPGA-Based Depthwise Separable Convolution Accelerator,‚Äù Electronics, 2023.

Cuong Pham-Quoc et al., ‚ÄúEfficient FPGA-Based CNN for Edge Computing,‚Äù MDPI Electronics, 2022.

ASIC Implementation for production-grade smart fab deployment.

Privacy-preserving inference for sensitive manufacturing data.
